<h1 id="s3-distributed-representations">S3: Distributed
representations</h1>
<p>This assignment is a part of the preparation for the seminar on 29
April.</p>
<p>Please have a look <a
href="https://canvas.gu.se/courses/51974/pages/seminar-assignments-and-discussions">here</a>
for how to prepare for the seminar.</p>
<p>In this seminar we will look at how we can learn distributed meaning
representations and language models using neural networks. Similarly to
the previous seminar we will discuss what semantic knowledge these
representations capture and how do they relate to the notion of
compositionality.</p>
<ul>
<li>Y. Bengio, R. Ducharme, P. Vincent, and C. Janvin. <a
href="https://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf">A
neural probabilistic language model.</a> Journal of Machine Learning
Research, 3(6):1137–1155, 2003. (Sections 3 and 4 are less relevant
today and hence you can glance through them quickly. Instead, look at
the Mikolov papers where they describe training word embeddings with the
current neural network architectures.)</li>
<li>M. Ghanimifard and S. Dobnik. <a
href="https://gup.ub.gu.se/publication/257763?lang=en">Learning to
compose spatial relations with grounded neural language models.</a><a
href="https://canvas.gu.se/courses/22914/files/2936161/download?download_frd=1"> </a>
In C. Gardent and C. Retoré, editors, Proceedings of IWCS 2017: 12th
International Conference on Computational Semantics, pages 1–12,
Montpellier, France, September 19–22 2017. Association for Computational
Linguistics.</li>
</ul>
<p>Optional but helpful background and further reading:</p>
<ul>
<li>T. Mikolov, K. Chen, G. Corrado, and J. Dean. <a
href="https://arxiv.org/pdf/1301.3781.pdf">Efficient estimation of word
representations in vector space.</a> arXiv preprint arXiv:1301.3781,
2013.</li>
<li>T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. <a
href="https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf">Distributed
representations of words and phrases and their compositionality.</a> In
Advances in neural information processing systems, pages 3111–3119,
2013.</li>
<li>M. Kågebäck and H. Salomonsson. <a
href="https://arxiv.org/pdf/1606.03568.pdf">Word sense disambiguation
using a bidirectional LSTM.</a> In 5th Workshop on Cognitive Aspects of
the Lexicon (CogALex). Association for Computational Linguistics,
2016.</li>
<li>C. Manning. <a
href="https://simons.berkeley.edu/talks/christopher-manning-2017-3-27">Representations
for language: From word embeddings to sentence meanings.</a> talk,
Stanford University, Simons Institute, Berkeley, March 27th 2017. <a
href="https://simons.berkeley.edu/sites/default/files/docs/6449/christophermanning.pdf">slides</a></li>
</ul>
<p>Below are some points that you may want to consider when reading
these papers.</p>
<p>For the first paper:</p>
<ul>
<li>Some concepts: syntagmatic and paradigmatic relations, one-hot
vector representation, dense embeddings, word2vec, CBOW, skip-gram,
Gensim, GloVe, LSTM</li>
<li>What is the difference between word embeddings, dsitributional word
vectors/matrices and word vectors with dimensionality reduction?</li>
<li>What are the benefits and weaknesses of using word embeddings
compared to other representations mentioned in the previous point both
in terms of the nature of representation and computational cost building
and using them?</li>
<li>What kind of word embeddings can we build; what are differences
between?</li>
<li>What is a probabilistic language model? How do word embeddings
relate to a probabilistic language model?</li>
</ul>
<p>For the second paper:</p>
<ul>
<li>Can compositionality be learned from data?</li>
<li>Why do we ground our language model in perceptual
informations/locations?</li>
<li>To what degree are distributional composed representations
interpretable?</li>
<li>Are the representations that we have learned the same as those as we
would expect from compositional rules?</li>
<li>Neural networks are also compositional models in the sense that they
are composed of units and each of these units defines some
representations. Do you agree?</li>
<li>To what degree can we say that a neural network has learned
compositional functions like those in formal semantics?</li>
</ul>
<p>The assignment is marked with complete/incomplete with a further
feedback on a 7 level scale where 4 is sufficient to complete the
assignment; 5 is good solid work; 6 is excellent work, covers most of
the assignment; and 7: creative work that goes beyond the
assignment.</p>
