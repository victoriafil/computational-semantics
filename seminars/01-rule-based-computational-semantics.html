<h2 id="seminar-1-rule-based-computational-semantics">Seminar 1:
Rule-based computational semantics</h2>
<p><a href="https://www.nltk.org/book/ch10.html">Analysing the meaning
of sentences</a> in S. Bird, E. Klein, and E. Loper. Natural language
processing with Python. O’Reilly, 2009.</p>
<h3 id="questions-to-discuss">Questions to discuss</h3>
<ul class="incremental">
<li>What are challenges of translating natural language to logic (in
general)?</li>
<li>Different logics are formal languages with specific properties: what
features of natural language they can represent and what are their
limitations?</li>
<li>How is underspecification of quantifier scope implemented in Cooper
storage?</li>
<li>How about other forms of underspecification in natural language,
e.g. lexical ambiguity?</li>
<li>Why do we need lambda calculus?</li>
<li>How can we use model builders and theorem provers (computational
tools) to check validity of arguments?</li>
<li>Do humans also reason this way?</li>
<li>Overall, what aspects of natural language semantics are treated well
with these methods and what aspects are not captured?</li>
<li>What NLP applications benefit from this approach?</li>
</ul>
<h3 id="simons-notes">Simon’s notes</h3>
<ul class="incremental">
<li><p>A lot is hard-wired into the grammar; composing semantic meaning
parallel to composition of syntactic constituents</p></li>
<li><p>Formal language and natural language: “and” vs <code>AND</code>,
“or” vs <code>OR</code></p></li>
<li><p>Logical equivalence</p></li>
<li><p>Pragmatic implicature:
<code>all x.(dog(x) -&gt; disappear(x))</code>; also true if there is no
dog in the model</p></li>
<li><p>More pragmatic constraints required are demonstrated when
demonstrating model building: e.g. to conclude from the first premise
that Adam loves Eve: sets of men and women are disjoint; Eve is the only
woman</p>
<pre><code>exists y. (woman(y) &amp; all x. (man(x) -&gt; love(x,y)))
man(adam)
woman(eve)
all x. (man(x) -&gt; -woman(x))
exists y. all x. (woman(x) -&gt; (x = y))
Goal: love(adam,eve)
</code></pre></li>
<li><p>Quantifier scope ambiguity: Everyone likes someone</p>
<ul class="incremental">
<li><code>all x.(person(x) -&gt; exists y.(person(y) &amp; admire(x,y)))</code></li>
<li><code>exists y.(person(y) &amp; all x.(person(x) -&gt; admire(x,y)))</code></li>
</ul></li>
<li><p>Consistent vs inconsistent propositions (i.e. those that are not
contradictory); can build a model of consistent descriptions</p></li>
<li><p>Can computer understand language? Turing test: natural language
understanding and generation at the level of <em>observable
behaviour</em></p></li>
<li><p>Theorem proving: can a prove (a proof goal) be derived by a
finite sequence of inference steps from a list of assumed formulas?;
<em>a valid argument</em></p></li>
<li><p>Model building: model building tries to create a new model, given
some set of sentences</p></li>
<li><p>Lambda calculus and transitive verbs</p>
<ul class="incremental">
<li>The verb phrases are:
<code>\y.exists x.(dog(x) &amp; chase(y, x))</code></li>
<li>Take out the verb:
<code>\P.exists x.(dog(x) &amp; P(x))(\z.chase(y, z))</code></li>
<li>Replace the NP part with a variable X:
<code>\P.exists x.(dog(x) &amp; P(x))</code></li>
<li><code>X(\z.chase(y, z))</code></li>
<li>Turn this into a function that will take an NP:
<code>\X y.X(\x.chase(y, x)) &lt;&lt;&lt;e,t&gt;,t&gt;,&lt;e,t&gt;&gt;</code></li>
</ul></li>
<li><p>Inference</p>
<ul class="incremental">
<li>Model building: negate the conclusion and add it to the premises; if
the we can build a model with a negated conclusion then it means that
there exists a model where premises are true and conclusion is false;
hence the conclusion cannot follow from the premises; if we cannot build
such a model then the conclusion is true; <em>hence fast when the
conclusion does not follow</em></li>
<li>Theorem proving: negate the conclusion and add it to the premises,
if we find a contradiction then it must be the cases that the conclusion
follows; if there is no contradiction among premises the negated
conclusion is consistent with premises; <em>hence fast when the
conclusion follows</em></li>
</ul></li>
<li><p>Cooper storage</p>
<ul class="incremental">
<li>Make the semantic representations underspecifed by removing
quantified expressions and replacing them with variables of type e</li>
<li><code>core = &lt;chase(z1,z2)&gt;</code></li>
<li><code>store = (bo(\P.all x.(girl(x) -&gt; P(x)),z1), bo(\P.exists x.(dog(x) &amp; P(x)),z2))</code></li>
</ul></li>
<li><p>Extensions to FOL required for</p>
<ul class="incremental">
<li>events, tense and aspect;</li>
<li>semantic roles;</li>
<li>generalized quantifiers such as <em>most</em>;</li>
<li>intensional constructions involving, for example, verbs like
<em>may</em> and <em>believe</em>.</li>
<li><ol class="incremental" type="i">
<li>and (ii) can be expressed in FOL; (iii) and (iV) require
extensions</li>
</ol></li>
</ul></li>
</ul>
<h3 id="from-the-class-vt23">From the class, VT23</h3>
<ul class="incremental">
<li>Program complexity for rule-based systems and processing time;
<ul class="incremental">
<li>but training ANNs is also time consuming</li>
<li>humans writing grammars also take time</li>
<li><a href="https://en.wikiquote.org/wiki/Fred_Jelinek"
class="uri">https://en.wikiquote.org/wiki/Fred_Jelinek</a></li>
</ul></li>
<li>Granulairty of representations required</li>
<li>Interpretability
<ul class="incremental">
<li>sensitive applications</li>
</ul></li>
<li>The use of formal representations
<ul class="incremental">
<li>context specific: sensitivity of appliations</li>
<li>low-resource scenarios where linguistic inference is required</li>
<li>can use rules to verify what has been learned</li>
</ul></li>
<li>Reliance on syntactic parsing and syntax
<ul class="incremental">
<li>inefficient?</li>
<li>what happenes if we encode everything in lambda calculus, the
grammaer would likely be more complex</li>
<li>allows us to map different sentences to canonical semantic
representations</li>
<li>disambiguation: syntactic and semantic explosion of readings</li>
</ul></li>
<li>Non-compositional expressions
<ul class="incremental">
<li>idioms</li>
<li>can decide the granualrity of lambda applications</li>
</ul></li>
</ul>
<h3 id="from-the-class-vt22">From the class, VT22</h3>
<ul class="incremental">
<li>Efficiency of databases and queries
<ul class="incremental">
<li>we need a complete database, understand the problem</li>
<li>separation of data and representations and language; SQL language is
connected to the storage; portability of systems</li>
<li>are relational databases enough?</li>
</ul></li>
<li>Translating NLP to logic, limitations of logic to cover linguistic
constructions
<ul class="incremental">
<li>I think Gothenburg is… I think that P where P is a proposition</li>
<li>Natural language is not “grammatical”: sarcasm, figurative language,
idioms (sequence of words or a single word); lexical semantics is not
dealt with; deictic representations, spatial relations</li>
<li>Why FOL? Tools available.</li>
<li>Logic and AI: SHRDLU, Winograd, <a
href="https://en.wikipedia.org/wiki/SHRDLU"
class="uri">https://en.wikipedia.org/wiki/SHRDLU</a></li>
<li>NLU and NLG</li>
<li>We don’t say everything we mean? Language in context</li>
</ul></li>
<li>Ambiguities: lexical ambiguities, can they be solved by logic;
pragmatics and slang
<ul class="incremental">
<li>resolving lexical ambiguities: resolving through word contexts,
e.g. rock (music), rock (stone); also depending on the context: in the
Spotify app</li>
<li>words in different social contexts: changing language; updated
contexts in the database?</li>
</ul></li>
<li>Lambda calculus: how to do it for non-European languages and
dialects
<ul class="incremental">
<li>ambiguity</li>
<li>apply to corpora and study semantic relations in spoken
language</li>
<li>cross-linguistic semantic representations</li>
</ul></li>
<li>Computational tools for reasoning and how do they relate to human
reasoning?</li>
<li>Cooper storage?</li>
<li>From logic to applications:
<ul class="incremental">
<li>a QA system for family members</li>
<li>solving logic riddles, games, <a
href="https://www.uni-bamberg.de/en/sme/teaching/bambirds/"
class="uri">https://www.uni-bamberg.de/en/sme/teaching/bambirds/</a></li>
<li>tools and representations: what is good for different tasks? Where
do we find resources?</li>
</ul></li>
</ul>
<h3 id="from-the-class-vt21">From the class, VT21</h3>
<pre><code>girl(x) &amp; walk (x)

all x exits y.girl(x) &amp; sleepy(y) -&gt; walk(x) &amp; likes(x,y)

T

F

\-&gt;

T F F

F T T

F T F

T T T
</code></pre>
