{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set 2 - Part 2: Inference\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the following instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "In this part you will work on a problem from the FraCaS test suite. The goal of this problem set is to extend the grammar for Cooper storage from the previous part, apply the sentences to a theorem prover and a model builder, analyse their results and conclude about the inference. Since every sentence may be translated to several formulae there will also be several inference steps and thus several results.\n",
    "\n",
    "\n",
    "\n",
    "### Pre-requisite knowledge\n",
    "\n",
    "From `problem-set-1`:\n",
    "- First order logic\n",
    "- Lambda calculus\n",
    "- Feature unification context free grammar\n",
    "\n",
    "From `problem-set-2-part1.ipynb`:\n",
    "- Cooper storage\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This task requires NLTK and Jupyter Notebook (IPython package).\n",
    "import nltk\n",
    "from nltk.grammar import FeatureGrammar\n",
    "from nltk.sem import cooper_storage as cs\n",
    "\n",
    "from utils import display_latex, display_translation, display_tree, display, Markdown\n",
    "from utils2 import sem_parser, evaluate_sentences, syntax, syntax_notv\n",
    "\n",
    "read_expr = nltk.sem.Expression.fromstring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.1 Extending the grammar [6 marks]\n",
    "\n",
    "Extend the grammar below so that it covers the sentences of the inference problem based on FraCaS problem 057.\n",
    "\n",
    "Several solutions are possible, also some that would not result in entailment. Our lexical knowledge about words leads us how to formalise them in first order logic. Therefore, make sure that you handle the PP attachment in a away that you will be able to show entailments between examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'a Portuguese delegate published the result on climate',\n",
    "    'a Portuguese delegate published a result',\n",
    "    'a Portuguese delegate published the result',\n",
    "    'a Portuguese published a result',\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code resolves the readings from the Cooper storage. We collect the readings in a dictionary where the key is a sentence string and the value is a list of readings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answers\n",
    "fcfg_storage_answers_1 = r\"\"\"\n",
    "### Replace X with their proper representations\n",
    "X -> 'Portuguese'\n",
    "X -> 'delegate'\n",
    "X -> 'published'\n",
    "X -> 'the'\n",
    "X -> 'result'\n",
    "X -> 'on' \n",
    "X -> 'climate'\n",
    "## Extend the other missig rules too\n",
    "\"\"\"\n",
    "\n",
    "# this is going to add new rules to the syntax:\n",
    "new_syntax = FeatureGrammar(\n",
    "    syntax.start(),\n",
    "    syntax.productions() + FeatureGrammar.fromstring(fcfg_storage_answers_1).productions()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_readings = sem_parser(sentences, new_syntax)\n",
    "\n",
    "# print all readings\n",
    "for i, (sent, semreps) in enumerate(sentence_readings.items()):\n",
    "    for semrep in semreps:\n",
    "        display_translation(f\"{i+1}. {sent}\", semrep)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Using Prover9 [4 marks in total]\n",
    "\n",
    "Show which readings of (1) entail a reading of (2). **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is something missing in this code. You will have to fix it, before you can run it.\n",
    "\n",
    "prover = ...\n",
    "\n",
    "def apply_theorem_prover(premises,goals):\n",
    "    for premise in sentence_readings[premises]:\n",
    "        for goal in sentence_readings[goals]:\n",
    "            print(\"Premise      : %s\" % (premise))\n",
    "            print(\"Goal         : %s\" % (goal))\n",
    "            print(\"Prover result: %s\" % (...))\n",
    "            print(10*'----')\n",
    "            \n",
    "apply_theorem_prover(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the readings of (1) entail all the readings of (2)? If not, why not? **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which readings of (1) entail a reading of (4). **[1 mark]** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is something missing in this code. You will have to fix it, before you can run it.\n",
    "\n",
    "apply_theorem_prover(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do all the readings of (1) entail all the readings of (4)? If not, why not? **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Using Mace [2 marks in total]\n",
    "\n",
    "Show whether (1) entails (3). **[1 mark]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is something missing in this code. \n",
    "\n",
    "def apply_model_builder(premises,goals):\n",
    "    for premise in sentence_readings[premises]:\n",
    "        for goal in sentence_readings[goals]:\n",
    "            print(\"Premise : %s\" % (premise))\n",
    "            print(\"Goal    : %s\" % (goal))\n",
    "            mc = nltk.MaceCommand(..., assumptions=...)\n",
    "            ...\n",
    "            print(\"a model:\")\n",
    "            print(mc.valuation)\n",
    "            print(10*'...')\n",
    "\n",
    "apply_model_builder(...,...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain why. **[1 mark]**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "** Your answer ***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This part of the assignment has a total of 12 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
